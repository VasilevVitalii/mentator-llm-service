# Copy this file to .env and customize the values

# GPU backend for node-llama-cpp (cuda, vulkan, metal, or leave empty for CPU)
# NOTE: This setting only affects LOCAL development runs (F5 in VSCode, npm start, etc.)
# Docker containers detect GPU automatically via start-docker.sh script and ignore this setting
NODE_LLAMA_CPP_GPU=cuda

# Docker Build Configuration
# Path to the default GGUF model that will be included in the Docker image
DOCKER_DEFAULT_MODEL=/home/vitalii/GGUF/qwen2.5-0.5b-instruct-q8_0.gguf

# Docker image name (without tag)
DOCKER_IMAGE_NAME=mentator-llm-service
